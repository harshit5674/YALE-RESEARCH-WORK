{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhBmPKT7Ntbu",
        "outputId": "a02971f5-90b7-44e5-d986-f6aa87730882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install spektral"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6XhCIiuOF3h",
        "outputId": "700607c5-46f9-48ee-c7b3-6723ea4ce230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spektral in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from spektral) (2.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from spektral) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from spektral) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.21.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from spektral) (4.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spektral) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from spektral) (2.23.0)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from spektral) (2.9.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from spektral) (1.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (4.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (2.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.12)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.50.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (0.27.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (2.9.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (2.9.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->spektral) (1.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2.0->spektral) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2.0->spektral) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (0.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.2.0->spektral) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow>=2.2.0->spektral) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->spektral) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.data import Dataset, DisjointLoader, Graph\n",
        "from spektral.layers import GCSConv, GlobalAvgPool\n",
        "from spektral.transforms.normalize_adj import NormalizeAdj"
      ],
      "metadata": {
        "id": "JibCfYEF6zmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r YALE-RESEARCH-WORK"
      ],
      "metadata": {
        "id": "vS4c3o4zoFOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/harshit5674/YALE-RESEARCH-WORK.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy0sVbBy68u5",
        "outputId": "c9d358f8-6a20-41b7-d3fc-1f00d3550e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YALE-RESEARCH-WORK'...\n",
            "remote: Enumerating objects: 25061, done.\u001b[K\n",
            "remote: Counting objects: 100% (25061/25061), done.\u001b[K\n",
            "remote: Compressing objects: 100% (326/326), done.\u001b[K\n",
            "remote: Total 25061 (delta 24954), reused 24827 (delta 24729), pack-reused 0\n",
            "Receiving objects: 100% (25061/25061), 9.69 MiB | 21.85 MiB/s, done.\n",
            "Resolving deltas: 100% (24954/24954), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBPl9EIx9Wu1",
        "outputId": "bda91e77-bad8-4138-ca72-813770cf00ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  YALE-RESEARCH-WORK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"YALE-RESEARCH-WORK/dataset_automata\""
      ],
      "metadata": {
        "id": "Jq84bhDU-SYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "      \n",
        "    def read(self):\n",
        "      output=[]\n",
        "      for i in range(0,11000):\n",
        "         data = np.load(os.path.join(path, f'graph_{i}.npz'))\n",
        "         output.append(Graph(x=data['x'], a=data['a'], e=data['e'],y=data['y']))\n",
        "        \n",
        "      return output"
      ],
      "metadata": {
        "id": "ZLrwzw439Y2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "xVnEin3q9kt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"YALE-RESEARCH-WORK/dataset_automata\""
      ],
      "metadata": {
        "id": "SVCtPEY99uHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = MyDataset(transforms=NormalizeAdj())"
      ],
      "metadata": {
        "id": "mTrge9Dg-wRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CqJBsPx-005",
        "outputId": "01acfe9f-75c7-456e-855e-1fac0ea294f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyDataset(n_graphs=11000)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZjaKpfa_EFf",
        "outputId": "71fff09f-05c9-4099-ae17-671d856672c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEvwWj1z_JOI",
        "outputId": "8b873bfb-ed08-48ab-99ac-c338f0c69957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]],\n",
              "\n",
              "       [[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.data import DisjointLoader\n",
        "from spektral.datasets import QM9\n",
        "from spektral.layers import ECCConv, GlobalSumPool\n",
        "\n",
        "################################################################################\n",
        "# Config\n",
        "################################################################################\n",
        "learning_rate = 1e-3  # Learning rate\n",
        "epochs = 10  # Number of training epochs\n",
        "batch_size = 32  # Batch size\n",
        "\n",
        "################################################################################\n",
        "# Load data\n",
        "################################################################################\n",
        "dataset = MyDataset(transforms=NormalizeAdj())  # Set amount=None to train on whole dataset\n",
        "\n",
        "# Parameters\n",
        "F = dataset.n_node_features  # Dimension of node features\n",
        "S = dataset.n_edge_features  # Dimension of edge features\n",
        "n_out = dataset.n_labels  # Dimension of the target\n",
        "\n",
        "# Train/test split\n",
        "idxs = np.random.permutation(len(dataset))\n",
        "split = int(0.9 * len(dataset))\n",
        "idx_tr, idx_te = np.split(idxs, [split])\n",
        "dataset_tr, dataset_te = dataset[idx_tr], dataset[idx_te]\n",
        "\n",
        "loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs)\n",
        "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, epochs=1)\n",
        "\n",
        "################################################################################\n",
        "# Build model\n",
        "################################################################################\n",
        "class Net(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = ECCConv(32, activation=\"relu\")\n",
        "        self.conv2 = ECCConv(32, activation=\"relu\")\n",
        "        self.global_pool = GlobalSumPool()\n",
        "        self.dense = Dense(n_out)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, a, e, i = inputs\n",
        "        x = self.conv1([x, a, e])\n",
        "        x = self.conv2([x, a, e])\n",
        "        output = self.global_pool([x, i])\n",
        "        output = self.dense(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "model = Net()\n",
        "optimizer = Adam(learning_rate)\n",
        "loss_fn = MeanSquaredError()\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Fit model\n",
        "################################################################################\n",
        "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
        "def train_step(inputs, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(target, predictions) + sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "step = loss = 0\n",
        "for batch in loader_tr:\n",
        "    step += 1\n",
        "    loss += train_step(*batch)\n",
        "    if step == loader_tr.steps_per_epoch:\n",
        "        step = 0\n",
        "        print(\"Loss: {}\".format(loss / loader_tr.steps_per_epoch))\n",
        "        loss = 0\n",
        "\n",
        "################################################################################\n",
        "# Evaluate model\n",
        "################################################################################\n",
        "print(\"Testing model\")\n",
        "loss = 0\n",
        "for batch in loader_te:\n",
        "    inputs, target = batch\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss += loss_fn(target, predictions)\n",
        "loss /= loader_te.steps_per_epoch\n",
        "print(\"Done. Test loss: {}\".format(loss))"
      ],
      "metadata": {
        "id": "nPVo6bvqAOzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4dd7e7a-75f4-4ca6-aa39-5813b943e775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
            "  np.random.shuffle(a)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 21.088125228881836\n",
            "Loss: 16.38985824584961\n",
            "Loss: 16.324182510375977\n",
            "Loss: 16.292743682861328\n",
            "Loss: 16.291414260864258\n",
            "Loss: 16.27716636657715\n",
            "Loss: 16.247962951660156\n",
            "Loss: 16.257850646972656\n",
            "Loss: 16.23634910583496\n",
            "Loss: 16.249011993408203\n",
            "Testing model\n",
            "Done. Test loss: 16.551034927368164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.data import DisjointLoader\n",
        "from spektral.datasets import TUDataset\n",
        "from spektral.layers import GINConv, GlobalAvgPool\n",
        "\n",
        "################################################################################\n",
        "# Config\n",
        "################################################################################\n",
        "learning_rate = 1e-3  # Learning rate\n",
        "channels = 128  # Hidden units\n",
        "layers = 3  # GIN layers\n",
        "epochs = 10  # Number of training epochs\n",
        "batch_size = 32  # Batch size\n",
        "\n",
        "################################################################################\n",
        "# Load data\n",
        "################################################################################\n",
        "dataset = MyDataset(transforms=NormalizeAdj())\n",
        "\n",
        "# Parameters\n",
        "F = dataset.n_node_features  # Dimension of node features\n",
        "n_out = dataset.n_labels  # Dimension of the target\n",
        "\n",
        "# Train/test split\n",
        "idxs = np.random.permutation(len(dataset))\n",
        "split = int(0.9 * len(dataset))\n",
        "idx_tr, idx_te = np.split(idxs, [split])\n",
        "dataset_tr, dataset_te = dataset[idx_tr], dataset[idx_te]\n",
        "\n",
        "loader_tr = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs)\n",
        "loader_te = DisjointLoader(dataset_te, batch_size=batch_size, epochs=1)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Build model\n",
        "################################################################################\n",
        "class GIN0(Model):\n",
        "    def __init__(self, channels, n_layers):\n",
        "        super().__init__()\n",
        "        self.conv1 = GINConv(channels, epsilon=0, mlp_hidden=[channels, channels])\n",
        "        self.convs = []\n",
        "        for _ in range(1, n_layers):\n",
        "            self.convs.append(\n",
        "                GINConv(channels, epsilon=0, mlp_hidden=[channels, channels])\n",
        "            )\n",
        "        self.pool = GlobalAvgPool()\n",
        "        self.dense1 = Dense(channels, activation=\"relu\")\n",
        "        self.dropout = Dropout(0.5)\n",
        "        self.dense2 = Dense(n_out, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, a, e, i = inputs\n",
        "        x = self.conv1([x, a,e])\n",
        "        for conv in self.convs:\n",
        "            x = conv([x, a, e])\n",
        "        x = self.pool([x,e, i])\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.dense2(x)\n",
        "\n",
        "\n",
        "# Build model\n",
        "model = GIN0(channels, layers)\n",
        "optimizer = Adam(learning_rate)\n",
        "loss_fn = CategoricalCrossentropy()\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Fit model\n",
        "################################################################################\n",
        "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
        "def train_step(inputs, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(target, predictions) + sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    acc = tf.reduce_mean(categorical_accuracy(target, predictions))\n",
        "    return loss, acc\n",
        "\n",
        "\n",
        "epoch = step = 0\n",
        "results = []\n",
        "for batch in loader_tr:\n",
        "    step += 1\n",
        "    loss, acc = train_step(*batch)\n",
        "    results.append((loss, acc))\n",
        "    if step == loader_tr.steps_per_epoch:\n",
        "        step = 0\n",
        "        epoch += 1\n",
        "        print(\"Ep. {} - Loss: {}. Acc: {}\".format(epoch, *np.mean(results, 0)))\n",
        "        results = []\n",
        "\n",
        "################################################################################\n",
        "# Evaluate model\n",
        "################################################################################\n",
        "results = []\n",
        "for batch in loader_te:\n",
        "    inputs, target = batch\n",
        "    predictions = model(inputs, training=False)\n",
        "    results.append(\n",
        "        (\n",
        "            loss_fn(target, predictions),\n",
        "            tf.reduce_mean(categorical_accuracy(target, predictions)),\n",
        "        )\n",
        "    )\n",
        "print(\"Done. Test loss: {}. Test acc: {}\".format(*np.mean(results, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vcimLIUVP26P",
        "outputId": "6df9ed64-fed9-4a71-a02b-5cafb5eace45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spektral/data/utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
            "  np.random.shuffle(a)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-3cb627d2fbbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader_tr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mloader_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileyevw27oa.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(inputs, target)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filez7zdo73r.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'conv'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spektral/layers/pooling/global_pool.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'disjoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'do_return'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'retval_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_return\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spektral/layers/pooling/global_pool.py\u001b[0m in \u001b[0;36melse_body_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                         \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                         \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_pooling_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'single'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-58-3cb627d2fbbd>\", line 81, in train_step  *\n        predictions = model(inputs, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filez7zdo73r.py\", line 26, in tf__call\n        x = ag__.converted_call(ag__.ld(self).pool, ([ag__.ld(x), ag__.ld(e), ag__.ld(i)],), None, fscope)\n    File \"/tmp/__autograph_generated_filegv53rviu.py\", line 70, in tf__call\n        ag__.if_stmt((ag__.ld(self).data_mode == 'disjoint'), if_body_2, else_body_2, get_state_2, set_state_2, ('do_return', 'retval_'), 2)\n    File \"/tmp/__autograph_generated_filegv53rviu.py\", line 66, in else_body_2\n        retval_ = ag__.converted_call(ag__.ld(self).batch_pooling_op, (ag__.ld(X),), dict(axis=(- 2), keepdims=(ag__.ld(self).data_mode == 'single')), fscope)\n\n    TypeError: Exception encountered when calling layer \"gin0_2\" (type GIN0).\n    \n    in user code:\n    \n        File \"<ipython-input-58-3cb627d2fbbd>\", line 63, in call  *\n            x = self.pool([x,e, i])\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/tmp/__autograph_generated_filegv53rviu.py\", line 70, in tf__call\n            ag__.if_stmt((ag__.ld(self).data_mode == 'disjoint'), if_body_2, else_body_2, get_state_2, set_state_2, ('do_return', 'retval_'), 2)\n        File \"/tmp/__autograph_generated_filegv53rviu.py\", line 66, in else_body_2\n            retval_ = ag__.converted_call(ag__.ld(self).batch_pooling_op, (ag__.ld(X),), dict(axis=(- 2), keepdims=(ag__.ld(self).data_mode == 'single')), fscope)\n    \n        TypeError: Exception encountered when calling layer \"global_avg_pool_4\" (type GlobalAvgPool).\n        \n        in user code:\n        \n            File \"/usr/local/lib/python3.7/dist-packages/spektral/layers/pooling/global_pool.py\", line 40, in call  *\n                X, axis=-2, keepdims=(self.data_mode == \"single\")\n        \n            TypeError: Cannot convert a list containing a tensor of dtype <dtype: 'int64'> to <dtype: 'float32'> (Tensor is: <tf.Tensor 'inputs_5:0' shape=(None,) dtype=int64>)\n        \n        \n        Call arguments received by layer \"global_avg_pool_4\" (type GlobalAvgPool):\n           inputs=['tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 2), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=int64)']\n    \n    \n    Call arguments received by layer \"gin0_2\" (type GIN0):\n       inputs=('tf.Tensor(shape=(None, 2), dtype=float32)', '<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f83f96b1c50>', 'tf.Tensor(shape=(None, 2), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=int64)')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qia0V6L1quoc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}